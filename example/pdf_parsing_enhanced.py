#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼·ç‰ˆ PDF è§£æç¯„ä¾‹ - åŸºæ–¼ demo/demo_gradio.py çš„é«˜éš API

æœ¬ç¯„ä¾‹ä½¿ç”¨ DotsOCRParser çš„é«˜éš APIï¼Œèˆ‡ demo ä¸­çš„å¯¦ç¾ä¿æŒä¸€è‡´ï¼Œ
èƒ½å¤ è§£æåŒ…å«æ··åˆä¸­è‹±æ–‡ã€è¡¨æ ¼ã€åœ–ç‰‡ã€å…¬å¼ç­‰è¤‡é›œå…§å®¹çš„ PDF æ–‡æª”ã€‚

ç‰¹è‰²åŠŸèƒ½ï¼š
- ä½¿ç”¨ç¶“éé©—è­‰çš„é«˜éš API
- è‡ªå‹•æ··åˆèªè¨€è­˜åˆ¥
- çµæ§‹åŒ–å…§å®¹æå–
- æ‰¹é‡è™•ç†æ”¯æ´
- èˆ‡ demo ä¿æŒä¸€è‡´çš„è§£æå“è³ª
"""

import os
import sys
import json
import tempfile
import uuid
import shutil
import re
from typing import Dict, List, Any, Optional
from pathlib import Path

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from dots_ocr.parser import DotsOCRParser
from dots_ocr.utils.doc_utils import load_images_from_pdf
from PIL import Image


class EnhancedPDFProcessor:
    """å¢å¼·ç‰ˆ PDF è™•ç†å™¨ï¼ŒåŸºæ–¼ demo çš„é«˜éš API"""
    
    def __init__(self, use_hf: bool = False, num_threads: int = 4, dpi: int = 200):
        """
        åˆå§‹åŒ– PDF è™•ç†å™¨
        
        Args:
            use_hf (bool): æ˜¯å¦ä½¿ç”¨ HuggingFace æ¨¡å‹
            num_threads (int): è™•ç†ç·šç¨‹æ•¸
            dpi (int): PDF æ¸²æŸ“ DPI
        """
        print(f"ğŸ”§ åˆå§‹åŒ–å¢å¼·ç‰ˆ PDF è™•ç†å™¨ (DPI: {dpi}, ç·šç¨‹: {num_threads})")
        
        self.parser = DotsOCRParser(
            use_hf=use_hf,
            num_thread=num_threads,
            dpi=dpi,
            output_dir="./pdf_output"
        )
        
        self.language_patterns = {
            'chinese': r'[\u4e00-\u9fff]',
            'english': r'[a-zA-Z]',
            'numbers': r'[0-9]',
            'punctuation': r'[.,;:!?()"\'-]'
        }
    
    def create_temp_session_dir(self) -> tuple:
        """å‰µå»ºè‡¨æ™‚æœƒè©±ç›®éŒ„"""
        session_id = uuid.uuid4().hex[:8]
        temp_dir = os.path.join(tempfile.gettempdir(), f"dots_ocr_enhanced_{session_id}")
        os.makedirs(temp_dir, exist_ok=True)
        return temp_dir, session_id
    
    def parse_pdf_with_api(self, pdf_path: str, prompt_mode: str = "prompt_layout_all_en") -> Dict[str, Any]:
        """
        ä½¿ç”¨é«˜éš API è§£æ PDFï¼ˆèˆ‡ demo ä¸€è‡´ï¼‰
        
        Args:
            pdf_path (str): PDF æª”æ¡ˆè·¯å¾‘
            prompt_mode (str): è§£ææ¨¡å¼
            
        Returns:
            Dict[str, Any]: è§£æçµæœ
        """
        if not os.path.exists(pdf_path):
            return {'success': False, 'error': 'PDF æª”æ¡ˆä¸å­˜åœ¨'}
        
        print(f"ğŸ“„ ä½¿ç”¨é«˜éš API è§£æ PDFï¼š{pdf_path}")
        
        # ä½¿ç”¨ parser çš„è¼¸å‡ºç›®éŒ„è€Œä¸æ˜¯è‡¨æ™‚ç›®éŒ„
        filename = f"enhanced_{uuid.uuid4().hex[:8]}"
        save_dir = os.path.join(self.parser.output_dir, filename)
        os.makedirs(save_dir, exist_ok=True)
        
        print(f"ğŸ“ è§£æçµæœå°‡ä¿å­˜åˆ°ï¼š{save_dir}")
        
        try:
            # ä½¿ç”¨ DotsOCRParser çš„é«˜éš APIï¼ˆèˆ‡ demo/demo_gradio.py ä¸€è‡´ï¼‰
            results = self.parser.parse_pdf(
                input_path=pdf_path,
                filename=filename,
                prompt_mode=prompt_mode,
                save_dir=save_dir
            )
            
            if not results:
                return {'success': False, 'error': 'è§£æå™¨æœªè¿”å›çµæœ'}
            
            # è™•ç†å¤šé çµæœ
            parsed_results = []
            all_md_content = []
            all_cells_data = []
            actual_files = []  # è¨˜éŒ„å¯¦éš›ç”Ÿæˆçš„æª”æ¡ˆ
            
            for i, result in enumerate(results):
                page_result = {
                    'page_no': result.get('page_no', i),
                    'layout_image': None,
                    'cells_data': None,
                    'md_content': None,
                    'filtered': False,
                    'file_path': pdf_path
                }
                
                # è®€å–ç‰ˆé¢åœ–ç‰‡
                if 'layout_image_path' in result and os.path.exists(result['layout_image_path']):
                    page_result['layout_image'] = Image.open(result['layout_image_path'])
                    actual_files.append(('layout_image', result['layout_image_path']))
                    print(f"âœ“ æ‰¾åˆ°ç‰ˆé¢åœ–ç‰‡ï¼š{result['layout_image_path']}")
                
                # è®€å– JSON è³‡æ–™
                if 'layout_info_path' in result and os.path.exists(result['layout_info_path']):
                    with open(result['layout_info_path'], 'r', encoding='utf-8') as f:
                        json_data = json.load(f)
                        page_result['cells_data'] = json_data
                        
                        # æª¢æŸ¥æ˜¯å¦ç‚º filtered é é¢ï¼ˆåŒ…å«å­—ä¸²è³‡æ–™è€Œéå­—å…¸åˆ—è¡¨ï¼‰
                        if result.get('filtered', False):
                            # filtered é é¢çš„ JSON æª”æ¡ˆåŒ…å«åŸå§‹å­—ä¸²å›æ‡‰ï¼Œè·³éçµæ§‹åŒ–åˆ†æ
                            print(f"âš ï¸ ç¬¬ {i} é è§£æå¤±æ•—ï¼ˆfiltered=Trueï¼‰ï¼Œè·³éçµæ§‹åŒ–åˆ†æ")
                        else:
                            # æ­£å¸¸é é¢åŒ…å«å­—å…¸åˆ—è¡¨ï¼Œå¯ä»¥é€²è¡Œçµæ§‹åŒ–åˆ†æ
                            if isinstance(json_data, list):
                                all_cells_data.extend(json_data)
                            else:
                                print(f"âš ï¸ ç¬¬ {i} é  JSON æ ¼å¼ç•°å¸¸ï¼Œé æœŸç‚ºåˆ—è¡¨ä½†å¾—åˆ° {type(json_data)}")
                    actual_files.append(('layout_json', result['layout_info_path']))
                    print(f"âœ“ æ‰¾åˆ°ä½ˆå±€ JSONï¼š{result['layout_info_path']}")
                
                # è®€å– Markdown å…§å®¹
                if 'md_content_path' in result and os.path.exists(result['md_content_path']):
                    with open(result['md_content_path'], 'r', encoding='utf-8') as f:
                        page_content = f.read()
                        page_result['md_content'] = page_content
                        all_md_content.append(page_content)
                    actual_files.append(('markdown', result['md_content_path']))
                    print(f"âœ“ æ‰¾åˆ° Markdownï¼š{result['md_content_path']}")
                
                page_result['filtered'] = result.get('filtered', False)
                parsed_results.append(page_result)
            
            combined_md = "\n\n---\n\n".join(all_md_content) if all_md_content else ""
            
            print(f"âœ… æˆåŠŸè§£æ {len(results)} é ï¼Œå…± {len(all_cells_data)} å€‹å…ƒç´ ")
            print(f"ğŸ“ æ‰€æœ‰æª”æ¡ˆå·²ä¿å­˜åˆ°ï¼š{save_dir}")
            
            # é¡¯ç¤ºç”Ÿæˆçš„æª”æ¡ˆåˆ—è¡¨
            if actual_files:
                print(f"\nğŸ“‹ ç”Ÿæˆçš„æª”æ¡ˆåˆ—è¡¨ï¼š")
                for file_type, file_path in actual_files:
                    print(f"  {file_type}: {file_path}")
            
            return {
                'success': True,
                'parsed_results': parsed_results,
                'combined_md_content': combined_md,
                'combined_cells_data': all_cells_data,
                'temp_dir': save_dir,  # ä½¿ç”¨å¯¦éš›çš„ä¿å­˜ç›®éŒ„
                'session_id': filename,
                'total_pages': len(results),
                'actual_files': actual_files
            }
            
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def detect_content_languages(self, text: str) -> Dict[str, float]:
        """æª¢æ¸¬æ–‡å­—å…§å®¹çš„èªè¨€åˆ†å¸ƒ"""
        if not text.strip():
            return {}
        
        total_chars = len(text)
        language_counts = {}
        
        for lang, pattern in self.language_patterns.items():
            matches = re.findall(pattern, text)
            count = len(matches)
            if count > 0:
                language_counts[lang] = count / total_chars
        
        return language_counts
    
    def analyze_structured_content(self, cells_data: List[Dict]) -> Dict[str, Any]:
        """åˆ†æçµæ§‹åŒ–å…§å®¹"""
        analysis = {
            'total_elements': len(cells_data),
            'content_types': {},
            'language_stats': {
                'chinese_elements': 0,
                'english_elements': 0,
                'mixed_elements': 0,
                'total_text_elements': 0
            },
            'element_types': {
                'tables': 0,
                'images': 0,
                'formulas': 0,
                'text_blocks': 0,
                'titles': 0
            },
            'text_by_type': {
                'chinese_text': [],
                'english_text': [],
                'mixed_text': [],
                'tables': [],
                'formulas': [],
                'titles': []
            }
        }
        
        for element in cells_data:
                
            category = element.get('category', 'Unknown')
            text = element.get('text', '')
            bbox = element.get('bbox', [])
            
            # çµ±è¨ˆå…§å®¹é¡å‹
            analysis['content_types'][category] = analysis['content_types'].get(category, 0) + 1
            
            # å…ƒç´ é¡å‹çµ±è¨ˆ
            if category == 'Table':
                analysis['element_types']['tables'] += 1
                analysis['text_by_type']['tables'].append({
                    'text': text, 'bbox': bbox, 'category': category
                })
            elif category == 'Picture':
                analysis['element_types']['images'] += 1
            elif category == 'Formula':
                analysis['element_types']['formulas'] += 1
                analysis['text_by_type']['formulas'].append({
                    'text': text, 'bbox': bbox, 'category': category
                })
            elif category in ['Title', 'Section-header']:
                analysis['element_types']['titles'] += 1
                analysis['text_by_type']['titles'].append({
                    'text': text, 'bbox': bbox, 'category': category
                })
            elif category in ['Text', 'List-item', 'Caption']:
                analysis['element_types']['text_blocks'] += 1
                
                # èªè¨€åˆ†æ
                if text.strip():
                    analysis['language_stats']['total_text_elements'] += 1
                    languages = self.detect_content_languages(text)
                    chinese_ratio = languages.get('chinese', 0)
                    english_ratio = languages.get('english', 0)
                    
                    element_info = {
                        'text': text, 'bbox': bbox, 'category': category,
                        'chinese_ratio': chinese_ratio, 'english_ratio': english_ratio
                    }
                    
                    if chinese_ratio > 0.5 and english_ratio < 0.1:
                        analysis['language_stats']['chinese_elements'] += 1
                        analysis['text_by_type']['chinese_text'].append(element_info)
                    elif english_ratio > 0.5 and chinese_ratio < 0.1:
                        analysis['language_stats']['english_elements'] += 1
                        analysis['text_by_type']['english_text'].append(element_info)
                    elif chinese_ratio > 0.1 and english_ratio > 0.1:
                        analysis['language_stats']['mixed_elements'] += 1
                        analysis['text_by_type']['mixed_text'].append(element_info)
                    else:
                        # é»˜èªæ­¸é¡ç‚ºè‹±æ–‡
                        analysis['language_stats']['english_elements'] += 1
                        analysis['text_by_type']['english_text'].append(element_info)
        
        return analysis
    
    def save_structured_results(self, analysis: Dict[str, Any], session_id: str, output_dir: str) -> str:
        """ä¿å­˜çµæ§‹åŒ–çµæœåˆ°ä¸åŒæª”æ¡ˆ"""
        structured_dir = os.path.join(output_dir, f"structured_{session_id}")
        os.makedirs(structured_dir, exist_ok=True)
        
        # ä¿å­˜ä¸­æ–‡å…§å®¹
        if analysis['text_by_type']['chinese_text']:
            chinese_file = os.path.join(structured_dir, "chinese_content.md")
            with open(chinese_file, 'w', encoding='utf-8') as f:
                f.write("# ä¸­æ–‡å…§å®¹\n\n")
                for i, item in enumerate(analysis['text_by_type']['chinese_text'], 1):
                    f.write(f"## å…§å®¹ {i} - {item['category']}\n\n")
                    f.write(f"**ä½ç½®**: {item['bbox']}\n\n")
                    f.write(f"{item['text']}\n\n")
            print(f"âœ“ ä¸­æ–‡å…§å®¹å·²ä¿å­˜ï¼š{chinese_file}")
        
        # ä¿å­˜è‹±æ–‡å…§å®¹
        if analysis['text_by_type']['english_text']:
            english_file = os.path.join(structured_dir, "english_content.md")
            with open(english_file, 'w', encoding='utf-8') as f:
                f.write("# English Content\n\n")
                for i, item in enumerate(analysis['text_by_type']['english_text'], 1):
                    f.write(f"## Content {i} - {item['category']}\n\n")
                    f.write(f"**Position**: {item['bbox']}\n\n")
                    f.write(f"{item['text']}\n\n")
            print(f"âœ“ è‹±æ–‡å…§å®¹å·²ä¿å­˜ï¼š{english_file}")
        
        # ä¿å­˜æ··åˆèªè¨€å…§å®¹
        if analysis['text_by_type']['mixed_text']:
            mixed_file = os.path.join(structured_dir, "mixed_language_content.md")
            with open(mixed_file, 'w', encoding='utf-8') as f:
                f.write("# ä¸­è‹±æ–‡æ··åˆå…§å®¹ / Mixed Language Content\n\n")
                for i, item in enumerate(analysis['text_by_type']['mixed_text'], 1):
                    chinese_pct = item.get('chinese_ratio', 0) * 100
                    english_pct = item.get('english_ratio', 0) * 100
                    f.write(f"## æ··åˆå…§å®¹ {i} - {item['category']}\n\n")
                    f.write(f"**èªè¨€åˆ†å¸ƒ**: ä¸­æ–‡ {chinese_pct:.1f}%, è‹±æ–‡ {english_pct:.1f}%\n\n")
                    f.write(f"**ä½ç½®**: {item['bbox']}\n\n")
                    f.write(f"{item['text']}\n\n")
            print(f"âœ“ æ··åˆèªè¨€å…§å®¹å·²ä¿å­˜ï¼š{mixed_file}")
        
        # ä¿å­˜è¡¨æ ¼å…§å®¹
        if analysis['text_by_type']['tables']:
            table_file = os.path.join(structured_dir, "tables.html")
            with open(table_file, 'w', encoding='utf-8') as f:
                f.write("<html><head><meta charset='utf-8'><title>è¡¨æ ¼å…§å®¹</title></head><body>\n")
                f.write("<h1>è¡¨æ ¼å…§å®¹</h1>\n")
                for i, item in enumerate(analysis['text_by_type']['tables'], 1):
                    f.write(f"<h2>è¡¨æ ¼ {i}</h2>\n")
                    f.write(f"<p><strong>ä½ç½®</strong>: {item['bbox']}</p>\n")
                    f.write(f"<div style='border: 1px solid #ccc; padding: 10px; margin: 10px 0;'>\n")
                    f.write(f"{item['text'].replace(chr(10), '<br>')}\n")
                    f.write("</div>\n")
                f.write("</body></html>")
            print(f"âœ“ è¡¨æ ¼å…§å®¹å·²ä¿å­˜ï¼š{table_file}")
        
        # ä¿å­˜åˆ†æå ±å‘Š
        report_file = os.path.join(structured_dir, "analysis_report.txt")
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("PDF å…§å®¹åˆ†æå ±å‘Š\n")
            f.write("=" * 30 + "\n\n")
            
            f.write("## ç¸½é«”çµ±è¨ˆ\n")
            f.write(f"ç¸½å…ƒç´ æ•¸ï¼š{analysis['total_elements']}\n")
            f.write(f"æ–‡å­—å…ƒç´ æ•¸ï¼š{analysis['language_stats']['total_text_elements']}\n")
            f.write(f"è¡¨æ ¼æ•¸ï¼š{analysis['element_types']['tables']}\n")
            f.write(f"åœ–ç‰‡æ•¸ï¼š{analysis['element_types']['images']}\n")
            f.write(f"å…¬å¼æ•¸ï¼š{analysis['element_types']['formulas']}\n")
            f.write(f"æ¨™é¡Œæ•¸ï¼š{analysis['element_types']['titles']}\n\n")
            
            f.write("## èªè¨€åˆ†å¸ƒ\n")
            f.write(f"ä¸­æ–‡å…ƒç´ ï¼š{analysis['language_stats']['chinese_elements']}\n")
            f.write(f"è‹±æ–‡å…ƒç´ ï¼š{analysis['language_stats']['english_elements']}\n")
            f.write(f"æ··åˆèªè¨€å…ƒç´ ï¼š{analysis['language_stats']['mixed_elements']}\n\n")
            
            f.write("## å…ƒç´ é¡å‹åˆ†å¸ƒ\n")
            for content_type, count in analysis['content_types'].items():
                f.write(f"{content_type}: {count}\n")
        
        print(f"âœ“ åˆ†æå ±å‘Šå·²ä¿å­˜ï¼š{report_file}")
        print(f"âœ… æ‰€æœ‰çµæ§‹åŒ–å…§å®¹å·²ä¿å­˜åˆ°ï¼š{structured_dir}")
        
        return structured_dir
    
    def process_pdf_enhanced(self, pdf_path: str, prompt_mode: str = "prompt_layout_all_en") -> Dict[str, Any]:
        """
        å¢å¼·ç‰ˆ PDF è™•ç†ï¼ˆå®Œæ•´æµç¨‹ï¼‰
        
        Args:
            pdf_path (str): PDF æª”æ¡ˆè·¯å¾‘
            prompt_mode (str): è§£ææ¨¡å¼
            
        Returns:
            Dict[str, Any]: å®Œæ•´è™•ç†çµæœ
        """
        print(f"ğŸš€ å•Ÿå‹•å¢å¼·ç‰ˆ PDF è™•ç†ï¼š{os.path.basename(pdf_path)}")
        
        # ç¬¬ä¸€æ­¥ï¼šä½¿ç”¨é«˜éš API è§£æ
        parse_result = self.parse_pdf_with_api(pdf_path, prompt_mode)
        
        if not parse_result['success']:
            return parse_result
        
        # ç¬¬äºŒæ­¥ï¼šçµæ§‹åŒ–å…§å®¹åˆ†æ
        print("ğŸ“Š é€²è¡Œçµæ§‹åŒ–å…§å®¹åˆ†æ...")
        analysis = self.analyze_structured_content(parse_result['combined_cells_data'])
        
        # ç¬¬ä¸‰æ­¥ï¼šä¿å­˜çµæ§‹åŒ–çµæœ
        print("ğŸ’¾ ä¿å­˜çµæ§‹åŒ–çµæœ...")
        structured_dir = self.save_structured_results(
            analysis, 
            parse_result['session_id'], 
            parse_result['temp_dir']
        )
        
        # ç¬¬å››æ­¥ï¼šç”Ÿæˆæ‘˜è¦
        summary = {
            'file_name': os.path.basename(pdf_path),
            'total_pages': parse_result['total_pages'],
            'total_elements': analysis['total_elements'],
            'chinese_elements': analysis['language_stats']['chinese_elements'],
            'english_elements': analysis['language_stats']['english_elements'],
            'mixed_elements': analysis['language_stats']['mixed_elements'],
            'tables': analysis['element_types']['tables'],
            'images': analysis['element_types']['images'],
            'formulas': analysis['element_types']['formulas'],
            'structured_output_dir': structured_dir
        }
        
        print(f"\nğŸ“‹ è™•ç†æ‘˜è¦ï¼š")
        print(f"  æª”æ¡ˆï¼š{summary['file_name']}")
        print(f"  é æ•¸ï¼š{summary['total_pages']}")
        print(f"  ç¸½å…ƒç´ ï¼š{summary['total_elements']}")
        print(f"  ä¸­æ–‡å…ƒç´ ï¼š{summary['chinese_elements']}")
        print(f"  è‹±æ–‡å…ƒç´ ï¼š{summary['english_elements']}")
        print(f"  æ··åˆèªè¨€å…ƒç´ ï¼š{summary['mixed_elements']}")
        print(f"  è¡¨æ ¼ï¼š{summary['tables']}")
        print(f"  åœ–ç‰‡ï¼š{summary['images']}")
        print(f"  å…¬å¼ï¼š{summary['formulas']}")
        
        return {
            'success': True,
            'summary': summary,
            'analysis': analysis,
            'parse_result': parse_result,
            'structured_dir': structured_dir
        }


def demo_enhanced_pdf_processing():
    """æ¼”ç¤ºå¢å¼·ç‰ˆ PDF è™•ç†åŠŸèƒ½"""
    print("ğŸ¯ å¢å¼·ç‰ˆ PDF è™•ç†æ¼”ç¤º")
    print("åŸºæ–¼ demo/demo_gradio.py çš„é«˜éš API")
    print("=" * 50)
    
    # å‰µå»ºè™•ç†å™¨
    processor = EnhancedPDFProcessor(
        use_hf=False,  # ä½¿ç”¨ vLLM ä»¥ç²å¾—æ›´å¥½çš„æ€§èƒ½
        num_threads=4,
        dpi=200  # èˆ‡ demo ä¸€è‡´çš„ DPI è¨­å®š
    )
    
    # æ¸¬è©¦æª”æ¡ˆåˆ—è¡¨
    test_files = [
        "../demo/demo_pdf1.pdf",
        "110120240613G01.pdf"
    ]
    
    print("\nğŸ“„ å¯ç”¨çš„æ¸¬è©¦æª”æ¡ˆï¼š")
    available_files = []
    for i, file_path in enumerate(test_files, 1):
        if os.path.exists(file_path):
            print(f"  {i}. {file_path} âœ…")
            available_files.append(file_path)
        else:
            print(f"  {i}. {file_path} âŒ")
    
    if not available_files:
        print("\nâŒ æ²’æœ‰æ‰¾åˆ°å¯ç”¨çš„æ¸¬è©¦æª”æ¡ˆ")
        return
    
    # ç”¨æˆ¶é¸æ“‡
    choice = input(f"\nè«‹é¸æ“‡æª”æ¡ˆ (1-{len(available_files)}) æˆ–è¼¸å…¥è‡ªå®šç¾©è·¯å¾‘: ").strip()
    
    if choice.isdigit() and 1 <= int(choice) <= len(available_files):
        pdf_path = available_files[int(choice) - 1]
    else:
        pdf_path = choice
        if not os.path.exists(pdf_path):
            print(f"âŒ æª”æ¡ˆä¸å­˜åœ¨ï¼š{pdf_path}")
            return
    
    print("\nğŸ”§ è§£ææ¨¡å¼ï¼š")
    print("1. prompt_layout_all_en - å®Œæ•´ç‰ˆé¢åˆ†æ")
    print("2. prompt_layout_only_en - åƒ…ç‰ˆé¢æª¢æ¸¬")
    print("3. prompt_ocr - åƒ…æ–‡å­—æå–")
    
    mode_choice = input("è«‹é¸æ“‡è§£ææ¨¡å¼ (1-3, é è¨­ 1): ").strip()
    mode_map = {
        "1": "prompt_layout_all_en",
        "2": "prompt_layout_only_en", 
        "3": "prompt_ocr",
        "": "prompt_layout_all_en"
    }
    prompt_mode = mode_map.get(mode_choice, "prompt_layout_all_en")
    
    print(f"\nğŸš€ é–‹å§‹è™•ç† {pdf_path}...")
    print(f"ğŸ“‹ è§£ææ¨¡å¼ï¼š{prompt_mode}")
    
    try:
        # åŸ·è¡Œå¢å¼·è™•ç†
        result = processor.process_pdf_enhanced(pdf_path, prompt_mode)
        
        if result['success']:
            print(f"\nğŸ‰ è™•ç†å®Œæˆï¼")
            print(f"ğŸ“ çµæ§‹åŒ–è¼¸å‡ºç›®éŒ„ï¼š{result['structured_dir']}")
            
            # é¡¯ç¤ºæ‰€æœ‰ç”Ÿæˆçš„æª”æ¡ˆ
            if 'actual_files' in result['parse_result']:
                print(f"\nğŸ“‹ è§£æç”Ÿæˆçš„æª”æ¡ˆï¼š")
                for file_type, file_path in result['parse_result']['actual_files']:
                    print(f"  {file_type}: {file_path}")
            
            # æª¢æŸ¥ä¸¦é¡¯ç¤ºçµæ§‹åŒ–æª”æ¡ˆ
            structured_dir = result['structured_dir']
            if os.path.exists(structured_dir):
                print(f"\nğŸ“‚ çµæ§‹åŒ–æª”æ¡ˆï¼š")
                for file in os.listdir(structured_dir):
                    file_path = os.path.join(structured_dir, file)
                    if os.path.isfile(file_path):
                        file_size = os.path.getsize(file_path)
                        print(f"  {file} ({file_size} bytes)")
            
            # è©¢å•æ˜¯å¦æŸ¥çœ‹çµæœ
            view_choice = input("\næ˜¯å¦æŸ¥çœ‹è™•ç†çµæœï¼Ÿ (y/n): ").strip().lower()
            if view_choice == 'y':
                # é¡¯ç¤º Markdown å…§å®¹é è¦½
                md_content = result['parse_result']['combined_md_content']
                if md_content:
                    print("\nğŸ“ Markdown å…§å®¹é è¦½ï¼ˆå‰500å­—ç¬¦ï¼‰ï¼š")
                    print("-" * 50)
                    print(md_content[:500])
                    if len(md_content) > 500:
                        print("...(æ›´å¤šå…§å®¹è«‹æŸ¥çœ‹è¼¸å‡ºæª”æ¡ˆ)")
                        
                # è©¢å•æ˜¯å¦æ‰“é–‹æª”æ¡ˆæ‰€åœ¨ç›®éŒ„
                open_choice = input("\næ˜¯å¦åœ¨æª”æ¡ˆç®¡ç†å™¨ä¸­æ‰“é–‹è¼¸å‡ºç›®éŒ„ï¼Ÿ (y/n): ").strip().lower()
                if open_choice == 'y':
                    output_dir = os.path.abspath(result['structured_dir'])
                    print(f"ğŸ“ è¼¸å‡ºç›®éŒ„ä½ç½®ï¼š{output_dir}")
                    # å˜—è©¦æ‰“é–‹æª”æ¡ˆç®¡ç†å™¨ï¼ˆLinuxï¼‰
                    try:
                        os.system(f"xdg-open '{output_dir}' 2>/dev/null || nautilus '{output_dir}' 2>/dev/null || echo 'è«‹æ‰‹å‹•æ‰“é–‹ç›®éŒ„ï¼š{output_dir}'")
                    except:
                        print(f"è«‹æ‰‹å‹•æ‰“é–‹ç›®éŒ„ï¼š{output_dir}")
        else:
            print(f"âŒ è™•ç†å¤±æ•—ï¼š{result['error']}")
            
    except Exception as e:
        print(f"âŒ è™•ç†éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    # è¨­ç½®å·¥ä½œç›®éŒ„
    os.chdir(os.path.dirname(os.path.abspath(__file__)))
    
    # å‰µå»ºè¼¸å‡ºç›®éŒ„
    os.makedirs("./pdf_output", exist_ok=True)
    
    try:
        demo_enhanced_pdf_processing()
        
        print("\n" + "=" * 60)
        print("ğŸ’¡ ä½¿ç”¨æç¤ºï¼š")
        print("1. æœ¬ç¯„ä¾‹ä½¿ç”¨èˆ‡ demo ç›¸åŒçš„é«˜éš API")
        print("2. è§£æå“è³ªèˆ‡ demo/demo_gradio.py ä¿æŒä¸€è‡´")
        print("3. è‡ªå‹•é€²è¡Œæ··åˆèªè¨€å…§å®¹åˆ†æ")
        print("4. çµæ§‹åŒ–è¼¸å‡ºä¾¿æ–¼å¾ŒçºŒè™•ç†")
        print("5. æ”¯æ´è¡¨æ ¼ã€åœ–ç‰‡ã€å…¬å¼çš„å°ˆé–€è™•ç†")
        print("=" * 60)
        
    except KeyboardInterrupt:
        print("\n\nâš  ç”¨æˆ¶ä¸­æ–·æ“ä½œ")
    except Exception as e:
        print(f"\nâŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        import traceback
        traceback.print_exc()