#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Â¢ûÂº∑Áâà PDF Ëß£ÊûêÁØÑ‰æã - Âü∫Êñº demo/demo_gradio.py ÁöÑÈ´òÈöé API

Êú¨ÁØÑ‰æã‰ΩøÁî® DotsOCRParser ÁöÑÈ´òÈöé APIÔºåËàá demo ‰∏≠ÁöÑÂØ¶Áèæ‰øùÊåÅ‰∏ÄËá¥Ôºå
ËÉΩÂ§†Ëß£ÊûêÂåÖÂê´Ê∑∑Âêà‰∏≠Ëã±Êñá„ÄÅË°®Ê†º„ÄÅÂúñÁâá„ÄÅÂÖ¨ÂºèÁ≠âË§áÈõúÂÖßÂÆπÁöÑ PDF ÊñáÊ™î„ÄÇ

ÁâπËâ≤ÂäüËÉΩÔºö
- ‰ΩøÁî®Á∂ìÈÅéÈ©óË≠âÁöÑÈ´òÈöé API
- Ëá™ÂãïÊ∑∑ÂêàË™ûË®ÄË≠òÂà•
- ÁµêÊßãÂåñÂÖßÂÆπÊèêÂèñ
- ÊâπÈáèËôïÁêÜÊîØÊè¥
- Ëàá demo ‰øùÊåÅ‰∏ÄËá¥ÁöÑËß£ÊûêÂìÅË≥™
"""

import os
import sys
import json
import tempfile
import uuid
import shutil
import re
from typing import Dict, List, Any, Optional
from pathlib import Path

# Ê∑ªÂä†Â∞àÊ°àÊ†πÁõÆÈåÑÂà∞ Python Ë∑ØÂæë
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from dots_ocr.parser import DotsOCRParser
from dots_ocr.utils.doc_utils import load_images_from_pdf
from PIL import Image


class EnhancedPDFProcessor:
    """Â¢ûÂº∑Áâà PDF ËôïÁêÜÂô®ÔºåÂü∫Êñº demo ÁöÑÈ´òÈöé API"""
    
    def __init__(self, use_hf: bool = False, num_threads: int = 4, dpi: int = 200):
        """
        ÂàùÂßãÂåñ PDF ËôïÁêÜÂô®
        
        Args:
            use_hf (bool): ÊòØÂê¶‰ΩøÁî® HuggingFace Ê®°Âûã
            num_threads (int): ËôïÁêÜÁ∑öÁ®ãÊï∏
            dpi (int): PDF Ê∏≤Êüì DPI
        """
        print(f"üîß ÂàùÂßãÂåñÂ¢ûÂº∑Áâà PDF ËôïÁêÜÂô® (DPI: {dpi}, Á∑öÁ®ã: {num_threads})")
        
        self.parser = DotsOCRParser(
            use_hf=use_hf,
            num_thread=num_threads,
            dpi=dpi,
            output_dir="./pdf_output"
        )
        
        self.language_patterns = {
            'chinese': r'[\u4e00-\u9fff]',
            'english': r'[a-zA-Z]',
            'numbers': r'[0-9]',
            'punctuation': r'[.,;:!?()"\'-]'
        }
    
    def create_temp_session_dir(self) -> tuple:
        """ÂâµÂª∫Ëá®ÊôÇÊúÉË©±ÁõÆÈåÑ"""
        session_id = uuid.uuid4().hex[:8]
        temp_dir = os.path.join(tempfile.gettempdir(), f"dots_ocr_enhanced_{session_id}")
        os.makedirs(temp_dir, exist_ok=True)
        return temp_dir, session_id
    
    def parse_pdf_with_api(self, pdf_path: str, prompt_mode: str = "prompt_layout_all_en") -> Dict[str, Any]:
        """
        ‰ΩøÁî®È´òÈöé API Ëß£Êûê PDFÔºàËàá demo ‰∏ÄËá¥Ôºâ
        
        Args:
            pdf_path (str): PDF Ê™îÊ°àË∑ØÂæë
            prompt_mode (str): Ëß£ÊûêÊ®°Âºè
            
        Returns:
            Dict[str, Any]: Ëß£ÊûêÁµêÊûú
        """
        if not os.path.exists(pdf_path):
            return {'success': False, 'error': 'PDF Ê™îÊ°à‰∏çÂ≠òÂú®'}
        
        print(f"üìÑ ‰ΩøÁî®È´òÈöé API Ëß£Êûê PDFÔºö{pdf_path}")
        
        # ‰ΩøÁî® parser ÁöÑËº∏Âá∫ÁõÆÈåÑËÄå‰∏çÊòØËá®ÊôÇÁõÆÈåÑ
        filename = f"enhanced_{uuid.uuid4().hex[:8]}"
        save_dir = os.path.join(self.parser.output_dir, filename)
        os.makedirs(save_dir, exist_ok=True)
        
        print(f"üìÅ Ëß£ÊûêÁµêÊûúÂ∞á‰øùÂ≠òÂà∞Ôºö{save_dir}")
        
        try:
            # ‰ΩøÁî® DotsOCRParser ÁöÑÈ´òÈöé APIÔºàËàá demo/demo_gradio.py ‰∏ÄËá¥Ôºâ
            results = self.parser.parse_pdf(
                input_path=pdf_path,
                filename=filename,
                prompt_mode=prompt_mode,
                save_dir=save_dir
            )
            
            if not results:
                return {'success': False, 'error': 'Ëß£ÊûêÂô®Êú™ËøîÂõûÁµêÊûú'}
            
            # ËôïÁêÜÂ§öÈ†ÅÁµêÊûú
            parsed_results = []
            all_md_content = []
            all_cells_data = []
            actual_files = []  # Ë®òÈåÑÂØ¶ÈöõÁîüÊàêÁöÑÊ™îÊ°à
            
            for i, result in enumerate(results):
                page_result = {
                    'page_no': result.get('page_no', i),
                    'layout_image': None,
                    'cells_data': None,
                    'md_content': None,
                    'filtered': False,
                    'file_path': pdf_path
                }
                
                # ËÆÄÂèñÁâàÈù¢ÂúñÁâá
                if 'layout_image_path' in result and os.path.exists(result['layout_image_path']):
                    page_result['layout_image'] = Image.open(result['layout_image_path'])
                    actual_files.append(('layout_image', result['layout_image_path']))
                    print(f"‚úì ÊâæÂà∞ÁâàÈù¢ÂúñÁâáÔºö{result['layout_image_path']}")
                
                # ËÆÄÂèñ JSON Ë≥áÊñô
                if 'layout_info_path' in result and os.path.exists(result['layout_info_path']):
                    with open(result['layout_info_path'], 'r', encoding='utf-8') as f:
                        json_data = json.load(f)
                        page_result['cells_data'] = json_data
                        
                        # Ê™¢Êü•ÊòØÂê¶ÁÇ∫ filtered È†ÅÈù¢ÔºàÂåÖÂê´Â≠ó‰∏≤Ë≥áÊñôËÄåÈùûÂ≠óÂÖ∏ÂàóË°®Ôºâ
                        if result.get('filtered', False):
                            # filtered È†ÅÈù¢ÁöÑ JSON Ê™îÊ°àÂåÖÂê´ÂéüÂßãÂ≠ó‰∏≤ÂõûÊáâÔºåË∑≥ÈÅéÁµêÊßãÂåñÂàÜÊûê
                            print(f"‚ö†Ô∏è Á¨¨ {i} È†ÅËß£ÊûêÂ§±ÊïóÔºàfiltered=TrueÔºâÔºåË∑≥ÈÅéÁµêÊßãÂåñÂàÜÊûê")
                        else:
                            # Ê≠£Â∏∏È†ÅÈù¢ÂåÖÂê´Â≠óÂÖ∏ÂàóË°®ÔºåÂèØ‰ª•ÈÄ≤Ë°åÁµêÊßãÂåñÂàÜÊûê
                            if isinstance(json_data, list):
                                all_cells_data.extend(json_data)
                            else:
                                print(f"‚ö†Ô∏è Á¨¨ {i} È†Å JSON Ê†ºÂºèÁï∞Â∏∏ÔºåÈ†êÊúüÁÇ∫ÂàóË°®‰ΩÜÂæóÂà∞ {type(json_data)}")
                    actual_files.append(('layout_json', result['layout_info_path']))
                    print(f"‚úì ÊâæÂà∞‰ΩàÂ±Ä JSONÔºö{result['layout_info_path']}")
                
                # ËÆÄÂèñ Markdown ÂÖßÂÆπ
                if 'md_content_path' in result and os.path.exists(result['md_content_path']):
                    with open(result['md_content_path'], 'r', encoding='utf-8') as f:
                        page_content = f.read()
                        page_result['md_content'] = page_content
                        all_md_content.append(page_content)
                    actual_files.append(('markdown', result['md_content_path']))
                    print(f"‚úì ÊâæÂà∞ MarkdownÔºö{result['md_content_path']}")
                
                page_result['filtered'] = result.get('filtered', False)
                parsed_results.append(page_result)
            
            combined_md = "\n\n---\n\n".join(all_md_content) if all_md_content else ""
            
            print(f"‚úÖ ÊàêÂäüËß£Êûê {len(results)} È†ÅÔºåÂÖ± {len(all_cells_data)} ÂÄãÂÖÉÁ¥†")
            print(f"üìÅ ÊâÄÊúâÊ™îÊ°àÂ∑≤‰øùÂ≠òÂà∞Ôºö{save_dir}")
            
            # È°ØÁ§∫ÁîüÊàêÁöÑÊ™îÊ°àÂàóË°®
            if actual_files:
                print(f"\nüìã ÁîüÊàêÁöÑÊ™îÊ°àÂàóË°®Ôºö")
                for file_type, file_path in actual_files:
                    print(f"  {file_type}: {file_path}")
            
            return {
                'success': True,
                'parsed_results': parsed_results,
                'combined_md_content': combined_md,
                'combined_cells_data': all_cells_data,
                'temp_dir': save_dir,  # ‰ΩøÁî®ÂØ¶ÈöõÁöÑ‰øùÂ≠òÁõÆÈåÑ
                'session_id': filename,
                'total_pages': len(results),
                'actual_files': actual_files
            }
            
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def detect_content_languages(self, text: str) -> Dict[str, float]:
        """Ê™¢Ê∏¨ÊñáÂ≠óÂÖßÂÆπÁöÑË™ûË®ÄÂàÜÂ∏É"""
        if not text.strip():
            return {}
        
        total_chars = len(text)
        language_counts = {}
        
        for lang, pattern in self.language_patterns.items():
            matches = re.findall(pattern, text)
            count = len(matches)
            if count > 0:
                language_counts[lang] = count / total_chars
        
        return language_counts
    
    def analyze_structured_content(self, cells_data: List[Dict]) -> Dict[str, Any]:
        """ÂàÜÊûêÁµêÊßãÂåñÂÖßÂÆπ"""
        analysis = {
            'total_elements': len(cells_data),
            'content_types': {},
            'language_stats': {
                'chinese_elements': 0,
                'english_elements': 0,
                'mixed_elements': 0,
                'total_text_elements': 0
            },
            'element_types': {
                'tables': 0,
                'images': 0,
                'formulas': 0,
                'text_blocks': 0,
                'titles': 0
            },
            'text_by_type': {
                'chinese_text': [],
                'english_text': [],
                'mixed_text': [],
                'tables': [],
                'formulas': [],
                'titles': []
            }
        }
        
        for element in cells_data:
                
            category = element.get('category', 'Unknown')
            text = element.get('text', '')
            bbox = element.get('bbox', [])
            
            # Áµ±Ë®àÂÖßÂÆπÈ°ûÂûã
            analysis['content_types'][category] = analysis['content_types'].get(category, 0) + 1
            
            # ÂÖÉÁ¥†È°ûÂûãÁµ±Ë®à
            if category == 'Table':
                analysis['element_types']['tables'] += 1
                analysis['text_by_type']['tables'].append({
                    'text': text, 'bbox': bbox, 'category': category
                })
            elif category == 'Picture':
                analysis['element_types']['images'] += 1
            elif category == 'Formula':
                analysis['element_types']['formulas'] += 1
                analysis['text_by_type']['formulas'].append({
                    'text': text, 'bbox': bbox, 'category': category
                })
            elif category in ['Title', 'Section-header']:
                analysis['element_types']['titles'] += 1
                analysis['text_by_type']['titles'].append({
                    'text': text, 'bbox': bbox, 'category': category
                })
            elif category in ['Text', 'List-item', 'Caption']:
                analysis['element_types']['text_blocks'] += 1
                
                # Ë™ûË®ÄÂàÜÊûê
                if text.strip():
                    analysis['language_stats']['total_text_elements'] += 1
                    languages = self.detect_content_languages(text)
                    chinese_ratio = languages.get('chinese', 0)
                    english_ratio = languages.get('english', 0)
                    
                    element_info = {
                        'text': text, 'bbox': bbox, 'category': category,
                        'chinese_ratio': chinese_ratio, 'english_ratio': english_ratio
                    }
                    
                    if chinese_ratio > 0.5 and english_ratio < 0.1:
                        analysis['language_stats']['chinese_elements'] += 1
                        analysis['text_by_type']['chinese_text'].append(element_info)
                    elif english_ratio > 0.5 and chinese_ratio < 0.1:
                        analysis['language_stats']['english_elements'] += 1
                        analysis['text_by_type']['english_text'].append(element_info)
                    elif chinese_ratio > 0.1 and english_ratio > 0.1:
                        analysis['language_stats']['mixed_elements'] += 1
                        analysis['text_by_type']['mixed_text'].append(element_info)
                    else:
                        # ÈªòË™çÊ≠∏È°ûÁÇ∫Ëã±Êñá
                        analysis['language_stats']['english_elements'] += 1
                        analysis['text_by_type']['english_text'].append(element_info)
        
        return analysis
    
    def save_structured_results(self, analysis: Dict[str, Any], session_id: str, output_dir: str) -> str:
        """‰øùÂ≠òÁµêÊßãÂåñÁµêÊûúÂà∞‰∏çÂêåÊ™îÊ°à"""
        structured_dir = os.path.join(output_dir, f"structured_{session_id}")
        os.makedirs(structured_dir, exist_ok=True)
        
        # ‰øùÂ≠ò‰∏≠ÊñáÂÖßÂÆπ
        if analysis['text_by_type']['chinese_text']:
            chinese_file = os.path.join(structured_dir, "chinese_content.md")
            with open(chinese_file, 'w', encoding='utf-8') as f:
                f.write("# ‰∏≠ÊñáÂÖßÂÆπ\n\n")
                for i, item in enumerate(analysis['text_by_type']['chinese_text'], 1):
                    f.write(f"## ÂÖßÂÆπ {i} - {item['category']}\n\n")
                    f.write(f"**‰ΩçÁΩÆ**: {item['bbox']}\n\n")
                    f.write(f"{item['text']}\n\n")
            print(f"‚úì ‰∏≠ÊñáÂÖßÂÆπÂ∑≤‰øùÂ≠òÔºö{chinese_file}")
        
        # ‰øùÂ≠òËã±ÊñáÂÖßÂÆπ
        if analysis['text_by_type']['english_text']:
            english_file = os.path.join(structured_dir, "english_content.md")
            with open(english_file, 'w', encoding='utf-8') as f:
                f.write("# English Content\n\n")
                for i, item in enumerate(analysis['text_by_type']['english_text'], 1):
                    f.write(f"## Content {i} - {item['category']}\n\n")
                    f.write(f"**Position**: {item['bbox']}\n\n")
                    f.write(f"{item['text']}\n\n")
            print(f"‚úì Ëã±ÊñáÂÖßÂÆπÂ∑≤‰øùÂ≠òÔºö{english_file}")
        
        # ‰øùÂ≠òÊ∑∑ÂêàË™ûË®ÄÂÖßÂÆπ
        if analysis['text_by_type']['mixed_text']:
            mixed_file = os.path.join(structured_dir, "mixed_language_content.md")
            with open(mixed_file, 'w', encoding='utf-8') as f:
                f.write("# ‰∏≠Ëã±ÊñáÊ∑∑ÂêàÂÖßÂÆπ / Mixed Language Content\n\n")
                for i, item in enumerate(analysis['text_by_type']['mixed_text'], 1):
                    chinese_pct = item.get('chinese_ratio', 0) * 100
                    english_pct = item.get('english_ratio', 0) * 100
                    f.write(f"## Ê∑∑ÂêàÂÖßÂÆπ {i} - {item['category']}\n\n")
                    f.write(f"**Ë™ûË®ÄÂàÜÂ∏É**: ‰∏≠Êñá {chinese_pct:.1f}%, Ëã±Êñá {english_pct:.1f}%\n\n")
                    f.write(f"**‰ΩçÁΩÆ**: {item['bbox']}\n\n")
                    f.write(f"{item['text']}\n\n")
            print(f"‚úì Ê∑∑ÂêàË™ûË®ÄÂÖßÂÆπÂ∑≤‰øùÂ≠òÔºö{mixed_file}")
        
        # ‰øùÂ≠òË°®Ê†ºÂÖßÂÆπ
        if analysis['text_by_type']['tables']:
            table_file = os.path.join(structured_dir, "tables.html")
            with open(table_file, 'w', encoding='utf-8') as f:
                f.write("<html><head><meta charset='utf-8'><title>Ë°®Ê†ºÂÖßÂÆπ</title></head><body>\n")
                f.write("<h1>Ë°®Ê†ºÂÖßÂÆπ</h1>\n")
                for i, item in enumerate(analysis['text_by_type']['tables'], 1):
                    f.write(f"<h2>Ë°®Ê†º {i}</h2>\n")
                    f.write(f"<p><strong>‰ΩçÁΩÆ</strong>: {item['bbox']}</p>\n")
                    f.write(f"<div style='border: 1px solid #ccc; padding: 10px; margin: 10px 0;'>\n")
                    f.write(f"{item['text'].replace(chr(10), '<br>')}\n")
                    f.write("</div>\n")
                f.write("</body></html>")
            print(f"‚úì Ë°®Ê†ºÂÖßÂÆπÂ∑≤‰øùÂ≠òÔºö{table_file}")
        
        # ‰øùÂ≠òÂàÜÊûêÂ†±Âëä
        report_file = os.path.join(structured_dir, "analysis_report.txt")
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("PDF ÂÖßÂÆπÂàÜÊûêÂ†±Âëä\n")
            f.write("=" * 30 + "\n\n")
            
            f.write("## Á∏ΩÈ´îÁµ±Ë®à\n")
            f.write(f"Á∏ΩÂÖÉÁ¥†Êï∏Ôºö{analysis['total_elements']}\n")
            f.write(f"ÊñáÂ≠óÂÖÉÁ¥†Êï∏Ôºö{analysis['language_stats']['total_text_elements']}\n")
            f.write(f"Ë°®Ê†ºÊï∏Ôºö{analysis['element_types']['tables']}\n")
            f.write(f"ÂúñÁâáÊï∏Ôºö{analysis['element_types']['images']}\n")
            f.write(f"ÂÖ¨ÂºèÊï∏Ôºö{analysis['element_types']['formulas']}\n")
            f.write(f"Ê®ôÈ°åÊï∏Ôºö{analysis['element_types']['titles']}\n\n")
            
            f.write("## Ë™ûË®ÄÂàÜÂ∏É\n")
            f.write(f"‰∏≠ÊñáÂÖÉÁ¥†Ôºö{analysis['language_stats']['chinese_elements']}\n")
            f.write(f"Ëã±ÊñáÂÖÉÁ¥†Ôºö{analysis['language_stats']['english_elements']}\n")
            f.write(f"Ê∑∑ÂêàË™ûË®ÄÂÖÉÁ¥†Ôºö{analysis['language_stats']['mixed_elements']}\n\n")
            
            f.write("## ÂÖÉÁ¥†È°ûÂûãÂàÜÂ∏É\n")
            for content_type, count in analysis['content_types'].items():
                f.write(f"{content_type}: {count}\n")
        
        print(f"‚úì ÂàÜÊûêÂ†±ÂëäÂ∑≤‰øùÂ≠òÔºö{report_file}")
        print(f"‚úÖ ÊâÄÊúâÁµêÊßãÂåñÂÖßÂÆπÂ∑≤‰øùÂ≠òÂà∞Ôºö{structured_dir}")
        
        return structured_dir
    
    def process_pdf_enhanced(self, pdf_path: str, prompt_mode: str = "prompt_layout_all_en") -> Dict[str, Any]:
        """
        Â¢ûÂº∑Áâà PDF ËôïÁêÜÔºàÂÆåÊï¥ÊµÅÁ®ãÔºâ
        
        Args:
            pdf_path (str): PDF Ê™îÊ°àË∑ØÂæë
            prompt_mode (str): Ëß£ÊûêÊ®°Âºè
            
        Returns:
            Dict[str, Any]: ÂÆåÊï¥ËôïÁêÜÁµêÊûú
        """
        print(f"üöÄ ÂïüÂãïÂ¢ûÂº∑Áâà PDF ËôïÁêÜÔºö{os.path.basename(pdf_path)}")
        
        # Á¨¨‰∏ÄÊ≠•Ôºö‰ΩøÁî®È´òÈöé API Ëß£Êûê
        parse_result = self.parse_pdf_with_api(pdf_path, prompt_mode)
        
        if not parse_result['success']:
            return parse_result
        
        # Á¨¨‰∫åÊ≠•ÔºöÁµêÊßãÂåñÂÖßÂÆπÂàÜÊûê
        print("üìä ÈÄ≤Ë°åÁµêÊßãÂåñÂÖßÂÆπÂàÜÊûê...")
        analysis = self.analyze_structured_content(parse_result['combined_cells_data'])
        
        # Á¨¨‰∏âÊ≠•Ôºö‰øùÂ≠òÁµêÊßãÂåñÁµêÊûú
        print("üíæ ‰øùÂ≠òÁµêÊßãÂåñÁµêÊûú...")
        structured_dir = self.save_structured_results(
            analysis, 
            parse_result['session_id'], 
            parse_result['temp_dir']
        )
        
        # Á¨¨ÂõõÊ≠•ÔºöÁîüÊàêÊëòË¶Å
        summary = {
            'file_name': os.path.basename(pdf_path),
            'total_pages': parse_result['total_pages'],
            'total_elements': analysis['total_elements'],
            'chinese_elements': analysis['language_stats']['chinese_elements'],
            'english_elements': analysis['language_stats']['english_elements'],
            'mixed_elements': analysis['language_stats']['mixed_elements'],
            'tables': analysis['element_types']['tables'],
            'images': analysis['element_types']['images'],
            'formulas': analysis['element_types']['formulas'],
            'structured_output_dir': structured_dir
        }
        
        print(f"\nüìã ËôïÁêÜÊëòË¶ÅÔºö")
        print(f"  Ê™îÊ°àÔºö{summary['file_name']}")
        print(f"  È†ÅÊï∏Ôºö{summary['total_pages']}")
        print(f"  Á∏ΩÂÖÉÁ¥†Ôºö{summary['total_elements']}")
        print(f"  ‰∏≠ÊñáÂÖÉÁ¥†Ôºö{summary['chinese_elements']}")
        print(f"  Ëã±ÊñáÂÖÉÁ¥†Ôºö{summary['english_elements']}")
        print(f"  Ê∑∑ÂêàË™ûË®ÄÂÖÉÁ¥†Ôºö{summary['mixed_elements']}")
        print(f"  Ë°®Ê†ºÔºö{summary['tables']}")
        print(f"  ÂúñÁâáÔºö{summary['images']}")
        print(f"  ÂÖ¨ÂºèÔºö{summary['formulas']}")
        
        return {
            'success': True,
            'summary': summary,
            'analysis': analysis,
            'parse_result': parse_result,
            'structured_dir': structured_dir
        }


def demo_enhanced_pdf_processing():
    """ÊºîÁ§∫Â¢ûÂº∑Áâà PDF ËôïÁêÜÂäüËÉΩ"""
    print("üéØ Â¢ûÂº∑Áâà PDF ËôïÁêÜÊºîÁ§∫")
    print("Âü∫Êñº demo/demo_gradio.py ÁöÑÈ´òÈöé API")
    print("=" * 50)
    
    # ÂâµÂª∫ËôïÁêÜÂô®
    processor = EnhancedPDFProcessor(
        use_hf=False,  # ‰ΩøÁî® vLLM ‰ª•Áç≤ÂæóÊõ¥Â•ΩÁöÑÊÄßËÉΩ
        num_threads=4,
        dpi=200  # Ëàá demo ‰∏ÄËá¥ÁöÑ DPI Ë®≠ÂÆö
    )
    
    # Ê∏¨Ë©¶Ê™îÊ°àÂàóË°®
    test_files = [
        "../demo/demo_pdf1.pdf",
        "110120240613G01.pdf"
    ]
    
    print("\nüìÑ ÂèØÁî®ÁöÑÊ∏¨Ë©¶Ê™îÊ°àÔºö")
    available_files = []
    for i, file_path in enumerate(test_files, 1):
        if os.path.exists(file_path):
            print(f"  {i}. {file_path} ‚úÖ")
            available_files.append(file_path)
        else:
            print(f"  {i}. {file_path} ‚ùå")
    
    if not available_files:
        print("\n‚ùå Ê≤íÊúâÊâæÂà∞ÂèØÁî®ÁöÑÊ∏¨Ë©¶Ê™îÊ°à")
        return
    
    # Áî®Êà∂ÈÅ∏Êìá
    choice = input(f"\nË´ãÈÅ∏ÊìáÊ™îÊ°à (1-{len(available_files)}) ÊàñËº∏ÂÖ•Ëá™ÂÆöÁæ©Ë∑ØÂæë: ").strip()
    
    if choice.isdigit() and 1 <= int(choice) <= len(available_files):
        pdf_path = available_files[int(choice) - 1]
    else:
        pdf_path = choice
        if not os.path.exists(pdf_path):
            print(f"‚ùå Ê™îÊ°à‰∏çÂ≠òÂú®Ôºö{pdf_path}")
            return
    
    print("\nüîß Ëß£ÊûêÊ®°ÂºèÔºö")
    print("1. prompt_layout_all_en - ÂÆåÊï¥ÁâàÈù¢ÂàÜÊûê")
    print("2. prompt_layout_only_en - ÂÉÖÁâàÈù¢Ê™¢Ê∏¨")
    print("3. prompt_ocr - ÂÉÖÊñáÂ≠óÊèêÂèñ")
    
    mode_choice = input("Ë´ãÈÅ∏ÊìáËß£ÊûêÊ®°Âºè (1-3, È†êË®≠ 1): ").strip()
    mode_map = {
        "1": "prompt_layout_all_en",
        "2": "prompt_layout_only_en", 
        "3": "prompt_ocr",
        "": "prompt_layout_all_en"
    }
    prompt_mode = mode_map.get(mode_choice, "prompt_layout_all_en")
    
    print(f"\nüöÄ ÈñãÂßãËôïÁêÜ {pdf_path}...")
    print(f"üìã Ëß£ÊûêÊ®°ÂºèÔºö{prompt_mode}")
    
    try:
        # Âü∑Ë°åÂ¢ûÂº∑ËôïÁêÜ
        result = processor.process_pdf_enhanced(pdf_path, prompt_mode)
        
        if result['success']:
            print(f"\nüéâ ËôïÁêÜÂÆåÊàêÔºÅ")
            print(f"üìÅ ÁµêÊßãÂåñËº∏Âá∫ÁõÆÈåÑÔºö{result['structured_dir']}")
            
            # È°ØÁ§∫ÊâÄÊúâÁîüÊàêÁöÑÊ™îÊ°à
            if 'actual_files' in result['parse_result']:
                print(f"\nüìã Ëß£ÊûêÁîüÊàêÁöÑÊ™îÊ°àÔºö")
                for file_type, file_path in result['parse_result']['actual_files']:
                    print(f"  {file_type}: {file_path}")
            
            # Ê™¢Êü•‰∏¶È°ØÁ§∫ÁµêÊßãÂåñÊ™îÊ°à
            structured_dir = result['structured_dir']
            if os.path.exists(structured_dir):
                print(f"\nüìÇ ÁµêÊßãÂåñÊ™îÊ°àÔºö")
                for file in os.listdir(structured_dir):
                    file_path = os.path.join(structured_dir, file)
                    if os.path.isfile(file_path):
                        file_size = os.path.getsize(file_path)
                        print(f"  {file} ({file_size} bytes)")
            
            # Ë©¢ÂïèÊòØÂê¶Êü•ÁúãÁµêÊûú
            view_choice = input("\nÊòØÂê¶Êü•ÁúãËôïÁêÜÁµêÊûúÔºü (y/n): ").strip().lower()
            if view_choice == 'y':
                # È°ØÁ§∫ Markdown ÂÖßÂÆπÈ†êË¶Ω
                md_content = result['parse_result']['combined_md_content']
                if md_content:
                    print("\nüìù Markdown ÂÖßÂÆπÈ†êË¶ΩÔºàÂâç500Â≠óÁ¨¶ÔºâÔºö")
                    print("-" * 50)
                    print(md_content[:500])
                    if len(md_content) > 500:
                        print("...(Êõ¥Â§öÂÖßÂÆπË´ãÊü•ÁúãËº∏Âá∫Ê™îÊ°à)")
                        
                # Ë©¢ÂïèÊòØÂê¶ÊâìÈñãÊ™îÊ°àÊâÄÂú®ÁõÆÈåÑ
                open_choice = input("\nÊòØÂê¶Âú®Ê™îÊ°àÁÆ°ÁêÜÂô®‰∏≠ÊâìÈñãËº∏Âá∫ÁõÆÈåÑÔºü (y/n): ").strip().lower()
                if open_choice == 'y':
                    output_dir = os.path.abspath(result['structured_dir'])
                    print(f"üìÅ Ëº∏Âá∫ÁõÆÈåÑ‰ΩçÁΩÆÔºö{output_dir}")
                    # ÂòóË©¶ÊâìÈñãÊ™îÊ°àÁÆ°ÁêÜÂô®ÔºàLinuxÔºâ
                    try:
                        os.system(f"xdg-open '{output_dir}' 2>/dev/null || nautilus '{output_dir}' 2>/dev/null || echo 'Ë´ãÊâãÂãïÊâìÈñãÁõÆÈåÑÔºö{output_dir}'")
                    except:
                        print(f"Ë´ãÊâãÂãïÊâìÈñãÁõÆÈåÑÔºö{output_dir}")
        else:
            print(f"‚ùå ËôïÁêÜÂ§±ÊïóÔºö{result['error']}")
            
    except Exception as e:
        print(f"‚ùå ËôïÁêÜÈÅéÁ®ã‰∏≠ÁôºÁîüÈåØË™§Ôºö{e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    # Ë®≠ÁΩÆÂ∑•‰ΩúÁõÆÈåÑ
    os.chdir(os.path.dirname(os.path.abspath(__file__)))
    
    # ÂâµÂª∫Ëº∏Âá∫ÁõÆÈåÑ
    os.makedirs("./pdf_output", exist_ok=True)
    
    try:
        demo_enhanced_pdf_processing()
        
        print("\n" + "=" * 60)
        print("üí° ‰ΩøÁî®ÊèêÁ§∫Ôºö")
        print("1. Êú¨ÁØÑ‰æã‰ΩøÁî®Ëàá demo Áõ∏ÂêåÁöÑÈ´òÈöé API")
        print("2. Ëß£ÊûêÂìÅË≥™Ëàá demo/demo_gradio.py ‰øùÊåÅ‰∏ÄËá¥")
        print("3. Ëá™ÂãïÈÄ≤Ë°åÊ∑∑ÂêàË™ûË®ÄÂÖßÂÆπÂàÜÊûê")
        print("4. ÁµêÊßãÂåñËº∏Âá∫‰æøÊñºÂæåÁ∫åËôïÁêÜ")
        print("5. ÊîØÊè¥Ë°®Ê†º„ÄÅÂúñÁâá„ÄÅÂÖ¨ÂºèÁöÑÂ∞àÈñÄËôïÁêÜ")
        print("=" * 60)
        
    except KeyboardInterrupt:
        print("\n\n‚ö† Áî®Êà∂‰∏≠Êñ∑Êìç‰Ωú")
    except Exception as e:
        print(f"\n‚ùå ÁôºÁîüÈåØË™§Ôºö{e}")
        import traceback
        traceback.print_exc()